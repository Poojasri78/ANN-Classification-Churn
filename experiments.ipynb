{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
       "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
       "1          2    15647311      Hill  ...               1       112542.58      0\n",
       "2          3    15619304      Onio  ...               0       113931.57      1\n",
       "3          4    15701354      Boni  ...               0        93826.63      0\n",
       "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('Churn_Modelling.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  ...  IsActiveMember  EstimatedSalary  Exited\n",
       "0             619    France  Female  ...               1        101348.88       1\n",
       "1             608     Spain  Female  ...               1        112542.58       0\n",
       "2             502    France  Female  ...               0        113931.57       1\n",
       "3             699    France  Female  ...               0         93826.63       0\n",
       "4             850     Spain  Female  ...               1         79084.10       0\n",
       "...           ...       ...     ...  ...             ...              ...     ...\n",
       "9995          771    France    Male  ...               0         96270.64       0\n",
       "9996          516    France    Male  ...               1        101699.77       0\n",
       "9997          709    France  Female  ...               1         42085.58       1\n",
       "9998          772   Germany    Male  ...               0         92888.52       1\n",
       "9999          792    France  Female  ...               0         38190.78       0\n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "# Dropping the irrelevant columns for prediction [RowNumber, CustomerId, Surname]\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  ...  IsActiveMember  EstimatedSalary  Exited\n",
       "0             619    France       0  ...               1        101348.88       1\n",
       "1             608     Spain       0  ...               1        112542.58       0\n",
       "2             502    France       0  ...               0        113931.57       1\n",
       "3             699    France       0  ...               0         93826.63       0\n",
       "4             850     Spain       0  ...               1         79084.10       0\n",
       "...           ...       ...     ...  ...             ...              ...     ...\n",
       "9995          771    France       1  ...               0         96270.64       0\n",
       "9996          516    France       1  ...               1        101699.77       0\n",
       "9997          709    France       0  ...               1         42085.58       1\n",
       "9998          772   Germany       1  ...               0         92888.52       1\n",
       "9999          792    France       0  ...               0         38190.78       0\n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding the categorical variable[Gender]\n",
    "label_encoder = LabelEncoder()\n",
    "data['Gender'] = label_encoder.fit_transform(data['Gender'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['France', 'Spain', 'Germany'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Geography'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding the categorical variable[Geography]\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder()\n",
    "onehot_encoder_geo = onehot_encoder.fit_transform(data[['Geography']])\n",
    "onehot_encoder_geo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder_geo.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Geography_France', 'Geography_Germany', 'Geography_Spain'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = onehot_encoder.get_feature_names_out(['Geography'])\n",
    "feature_names  # ['Geography_France', 'Geography_Spain', 'Geography_Germany']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Geography_France  Geography_Germany  Geography_Spain\n",
       "0                  1.0                0.0              0.0\n",
       "1                  0.0                0.0              1.0\n",
       "2                  1.0                0.0              0.0\n",
       "3                  1.0                0.0              0.0\n",
       "4                  0.0                0.0              1.0\n",
       "...                ...                ...              ...\n",
       "9995               1.0                0.0              0.0\n",
       "9996               1.0                0.0              0.0\n",
       "9997               1.0                0.0              0.0\n",
       "9998               0.0                1.0              0.0\n",
       "9999               1.0                0.0              0.0\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df_geo = pd.DataFrame(onehot_encoder_geo.toarray(),columns=feature_names)\n",
    "encoded_df_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  ...  Geography_Germany  Geography_Spain\n",
       "0             619       0  ...                0.0              0.0\n",
       "1             608       0  ...                0.0              1.0\n",
       "2             502       0  ...                0.0              0.0\n",
       "3             699       0  ...                0.0              0.0\n",
       "4             850       0  ...                0.0              1.0\n",
       "...           ...     ...  ...                ...              ...\n",
       "9995          771       1  ...                0.0              0.0\n",
       "9996          516       1  ...                0.0              0.0\n",
       "9997          709       0  ...                0.0              0.0\n",
       "9998          772       1  ...                1.0              0.0\n",
       "9999          792       0  ...                0.0              0.0\n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the original data with the encoded data\n",
    "data = pd.concat([data.drop('Geography',axis=1), encoded_df_geo], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the encoder and scaler\n",
    "with open('label_encoder.pkl', 'wb') as file:\n",
    "    pickle.dump(label_encoder, file)\n",
    "\n",
    "with open('onehot_encoder.pkl', 'wb') as file:\n",
    "    pickle.dump(onehot_encoder, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into features and target\n",
    "X = data.drop('Exited', axis = 1)\n",
    "y = data['Exited']\n",
    "\n",
    "# Split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\pooja\\miniconda3\\envs\\udemy\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\pooja\\miniconda3\\envs\\udemy\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\pooja\\miniconda3\\envs\\udemy\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pooja\\miniconda3\\envs\\udemy\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\pooja\\miniconda3\\envs\\udemy\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\pooja\\miniconda3\\envs\\udemy\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\pooja\\miniconda3\\envs\\udemy\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.2)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading grpcio-1.70.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading keras-3.9.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\pooja\\miniconda3\\envs\\udemy\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Collecting h5py>=3.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading h5py-3.13.0-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\pooja\\miniconda3\\envs\\udemy\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\pooja\\miniconda3\\envs\\udemy\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading optree-0.14.1-cp312-cp312-win_amd64.whl.metadata (50 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pooja\\miniconda3\\envs\\udemy\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pooja\\miniconda3\\envs\\udemy\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pooja\\miniconda3\\envs\\udemy\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pooja\\miniconda3\\envs\\udemy\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2025.1.31)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\pooja\\miniconda3\\envs\\udemy\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\pooja\\miniconda3\\envs\\udemy\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\pooja\\miniconda3\\envs\\udemy\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pooja\\miniconda3\\envs\\udemy\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\pooja\\miniconda3\\envs\\udemy\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
      "   ---------------------------------------- 0.0/390.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.4/390.3 MB 20.0 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 10.2/390.3 MB 26.6 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 13.9/390.3 MB 24.2 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 16.5/390.3 MB 21.2 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 17.0/390.3 MB 17.6 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 17.6/390.3 MB 14.4 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 18.1/390.3 MB 12.4 MB/s eta 0:00:31\n",
      "   - -------------------------------------- 18.6/390.3 MB 11.3 MB/s eta 0:00:33\n",
      "   - -------------------------------------- 19.1/390.3 MB 10.4 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 19.9/390.3 MB 9.6 MB/s eta 0:00:39\n",
      "   -- ------------------------------------- 20.7/390.3 MB 9.0 MB/s eta 0:00:41\n",
      "   -- ------------------------------------- 21.5/390.3 MB 8.5 MB/s eta 0:00:44\n",
      "   -- ------------------------------------- 22.3/390.3 MB 8.2 MB/s eta 0:00:45\n",
      "   -- ------------------------------------- 23.1/390.3 MB 7.9 MB/s eta 0:00:47\n",
      "   -- ------------------------------------- 24.1/390.3 MB 7.6 MB/s eta 0:00:48\n",
      "   -- ------------------------------------- 24.9/390.3 MB 7.5 MB/s eta 0:00:49\n",
      "   -- ------------------------------------- 25.4/390.3 MB 7.1 MB/s eta 0:00:52\n",
      "   -- ------------------------------------- 26.0/390.3 MB 6.9 MB/s eta 0:00:53\n",
      "   -- ------------------------------------- 26.5/390.3 MB 6.7 MB/s eta 0:00:55\n",
      "   -- ------------------------------------- 27.3/390.3 MB 6.5 MB/s eta 0:00:57\n",
      "   -- ------------------------------------- 28.0/390.3 MB 6.4 MB/s eta 0:00:58\n",
      "   -- ------------------------------------- 28.6/390.3 MB 6.2 MB/s eta 0:00:58\n",
      "   --- ------------------------------------ 29.6/390.3 MB 6.1 MB/s eta 0:00:59\n",
      "   --- ------------------------------------ 30.4/390.3 MB 6.0 MB/s eta 0:01:00\n",
      "   --- ------------------------------------ 31.2/390.3 MB 6.0 MB/s eta 0:01:01\n",
      "   --- ------------------------------------ 32.2/390.3 MB 5.9 MB/s eta 0:01:01\n",
      "   --- ------------------------------------ 33.3/390.3 MB 5.9 MB/s eta 0:01:01\n",
      "   --- ------------------------------------ 34.6/390.3 MB 5.9 MB/s eta 0:01:01\n",
      "   --- ------------------------------------ 35.7/390.3 MB 5.9 MB/s eta 0:01:01\n",
      "   --- ------------------------------------ 37.0/390.3 MB 5.9 MB/s eta 0:01:00\n",
      "   --- ------------------------------------ 38.3/390.3 MB 5.9 MB/s eta 0:01:00\n",
      "   ---- ----------------------------------- 39.8/390.3 MB 5.9 MB/s eta 0:01:00\n",
      "   ---- ----------------------------------- 41.4/390.3 MB 6.0 MB/s eta 0:00:59\n",
      "   ---- ----------------------------------- 43.0/390.3 MB 6.0 MB/s eta 0:00:58\n",
      "   ---- ----------------------------------- 44.6/390.3 MB 6.1 MB/s eta 0:00:58\n",
      "   ---- ----------------------------------- 46.1/390.3 MB 6.1 MB/s eta 0:00:57\n",
      "   ---- ----------------------------------- 47.4/390.3 MB 6.1 MB/s eta 0:00:57\n",
      "   ----- ---------------------------------- 49.0/390.3 MB 6.1 MB/s eta 0:00:56\n",
      "   ----- ---------------------------------- 50.9/390.3 MB 6.2 MB/s eta 0:00:55\n",
      "   ----- ---------------------------------- 52.7/390.3 MB 6.3 MB/s eta 0:00:54\n",
      "   ----- ---------------------------------- 54.5/390.3 MB 6.3 MB/s eta 0:00:53\n",
      "   ----- ---------------------------------- 56.6/390.3 MB 6.4 MB/s eta 0:00:53\n",
      "   ------ --------------------------------- 58.7/390.3 MB 6.5 MB/s eta 0:00:52\n",
      "   ------ --------------------------------- 60.8/390.3 MB 6.6 MB/s eta 0:00:51\n",
      "   ------ --------------------------------- 63.2/390.3 MB 6.7 MB/s eta 0:00:50\n",
      "   ------ --------------------------------- 65.3/390.3 MB 6.7 MB/s eta 0:00:49\n",
      "   ------ --------------------------------- 67.6/390.3 MB 6.8 MB/s eta 0:00:48\n",
      "   ------- -------------------------------- 70.3/390.3 MB 6.9 MB/s eta 0:00:47\n",
      "   ------- -------------------------------- 72.6/390.3 MB 7.0 MB/s eta 0:00:46\n",
      "   ------- -------------------------------- 75.0/390.3 MB 7.1 MB/s eta 0:00:45\n",
      "   ------- -------------------------------- 75.8/390.3 MB 7.1 MB/s eta 0:00:45\n",
      "   ------- -------------------------------- 76.3/390.3 MB 7.0 MB/s eta 0:00:45\n",
      "   ------- -------------------------------- 76.5/390.3 MB 6.9 MB/s eta 0:00:46\n",
      "   ------- -------------------------------- 76.8/390.3 MB 6.8 MB/s eta 0:00:47\n",
      "   ------- -------------------------------- 77.1/390.3 MB 6.7 MB/s eta 0:00:47\n",
      "   ------- -------------------------------- 77.3/390.3 MB 6.6 MB/s eta 0:00:48\n",
      "   ------- -------------------------------- 77.6/390.3 MB 6.4 MB/s eta 0:00:49\n",
      "   ------- -------------------------------- 77.6/390.3 MB 6.4 MB/s eta 0:00:49\n",
      "   ------- -------------------------------- 77.9/390.3 MB 6.3 MB/s eta 0:00:50\n",
      "   -------- ------------------------------- 78.4/390.3 MB 6.2 MB/s eta 0:00:51\n",
      "   -------- ------------------------------- 79.2/390.3 MB 6.1 MB/s eta 0:00:51\n",
      "   -------- ------------------------------- 80.0/390.3 MB 6.1 MB/s eta 0:00:52\n",
      "   -------- ------------------------------- 80.5/390.3 MB 6.1 MB/s eta 0:00:52\n",
      "   -------- ------------------------------- 81.5/390.3 MB 6.0 MB/s eta 0:00:52\n",
      "   -------- ------------------------------- 82.3/390.3 MB 6.0 MB/s eta 0:00:52\n",
      "   -------- ------------------------------- 83.4/390.3 MB 6.0 MB/s eta 0:00:52\n",
      "   -------- ------------------------------- 84.4/390.3 MB 5.9 MB/s eta 0:00:52\n",
      "   -------- ------------------------------- 85.5/390.3 MB 5.9 MB/s eta 0:00:52\n",
      "   -------- ------------------------------- 86.5/390.3 MB 5.9 MB/s eta 0:00:52\n",
      "   --------- ------------------------------ 87.8/390.3 MB 5.9 MB/s eta 0:00:52\n",
      "   --------- ------------------------------ 89.1/390.3 MB 5.9 MB/s eta 0:00:51\n",
      "   --------- ------------------------------ 90.4/390.3 MB 5.9 MB/s eta 0:00:51\n",
      "   --------- ------------------------------ 91.8/390.3 MB 5.9 MB/s eta 0:00:51\n",
      "   --------- ------------------------------ 93.3/390.3 MB 6.0 MB/s eta 0:00:50\n",
      "   --------- ------------------------------ 94.9/390.3 MB 6.0 MB/s eta 0:00:50\n",
      "   --------- ------------------------------ 96.5/390.3 MB 6.0 MB/s eta 0:00:50\n",
      "   ---------- ----------------------------- 98.3/390.3 MB 6.0 MB/s eta 0:00:49\n",
      "   ---------- ----------------------------- 100.1/390.3 MB 6.0 MB/s eta 0:00:48\n",
      "   ---------- ----------------------------- 101.7/390.3 MB 6.1 MB/s eta 0:00:48\n",
      "   ---------- ----------------------------- 103.8/390.3 MB 6.1 MB/s eta 0:00:47\n",
      "   ---------- ----------------------------- 105.4/390.3 MB 6.1 MB/s eta 0:00:47\n",
      "   ----------- ---------------------------- 107.5/390.3 MB 6.2 MB/s eta 0:00:46\n",
      "   ----------- ---------------------------- 109.6/390.3 MB 6.2 MB/s eta 0:00:46\n",
      "   ----------- ---------------------------- 111.7/390.3 MB 6.3 MB/s eta 0:00:45\n",
      "   ----------- ---------------------------- 113.8/390.3 MB 6.3 MB/s eta 0:00:44\n",
      "   ----------- ---------------------------- 115.9/390.3 MB 6.4 MB/s eta 0:00:44\n",
      "   ------------ --------------------------- 118.2/390.3 MB 6.4 MB/s eta 0:00:43\n",
      "   ------------ --------------------------- 120.6/390.3 MB 6.5 MB/s eta 0:00:42\n",
      "   ------------ --------------------------- 122.9/390.3 MB 6.5 MB/s eta 0:00:42\n",
      "   ------------ --------------------------- 125.3/390.3 MB 6.6 MB/s eta 0:00:41\n",
      "   ------------- -------------------------- 127.9/390.3 MB 6.6 MB/s eta 0:00:40\n",
      "   ------------- -------------------------- 130.5/390.3 MB 6.7 MB/s eta 0:00:39\n",
      "   ------------- -------------------------- 133.2/390.3 MB 6.8 MB/s eta 0:00:39\n",
      "   ------------- -------------------------- 135.8/390.3 MB 6.8 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 138.4/390.3 MB 6.9 MB/s eta 0:00:37\n",
      "   -------------- ------------------------- 141.3/390.3 MB 6.9 MB/s eta 0:00:36\n",
      "   -------------- ------------------------- 144.2/390.3 MB 7.0 MB/s eta 0:00:36\n",
      "   --------------- ------------------------ 147.3/390.3 MB 7.1 MB/s eta 0:00:35\n",
      "   --------------- ------------------------ 150.5/390.3 MB 7.2 MB/s eta 0:00:34\n",
      "   --------------- ------------------------ 153.4/390.3 MB 7.2 MB/s eta 0:00:33\n",
      "   ---------------- ----------------------- 156.8/390.3 MB 7.3 MB/s eta 0:00:32\n",
      "   ---------------- ----------------------- 159.4/390.3 MB 7.4 MB/s eta 0:00:32\n",
      "   ---------------- ----------------------- 162.3/390.3 MB 7.4 MB/s eta 0:00:31\n",
      "   ---------------- ----------------------- 165.7/390.3 MB 7.5 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 167.8/390.3 MB 7.5 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 169.6/390.3 MB 7.5 MB/s eta 0:00:30\n",
      "   ----------------- ---------------------- 171.4/390.3 MB 7.6 MB/s eta 0:00:29\n",
      "   ----------------- ---------------------- 173.5/390.3 MB 7.6 MB/s eta 0:00:29\n",
      "   ----------------- ---------------------- 175.4/390.3 MB 7.6 MB/s eta 0:00:29\n",
      "   ------------------ --------------------- 177.5/390.3 MB 7.6 MB/s eta 0:00:29\n",
      "   ------------------ --------------------- 179.6/390.3 MB 7.6 MB/s eta 0:00:28\n",
      "   ------------------ --------------------- 181.7/390.3 MB 7.6 MB/s eta 0:00:28\n",
      "   ------------------ --------------------- 183.8/390.3 MB 7.7 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 186.1/390.3 MB 7.7 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 188.2/390.3 MB 7.7 MB/s eta 0:00:27\n",
      "   ------------------- -------------------- 190.3/390.3 MB 7.7 MB/s eta 0:00:26\n",
      "   ------------------- -------------------- 192.9/390.3 MB 7.8 MB/s eta 0:00:26\n",
      "   -------------------- ------------------- 195.3/390.3 MB 7.8 MB/s eta 0:00:26\n",
      "   -------------------- ------------------- 197.7/390.3 MB 7.8 MB/s eta 0:00:25\n",
      "   -------------------- ------------------- 199.8/390.3 MB 7.8 MB/s eta 0:00:25\n",
      "   -------------------- ------------------- 202.4/390.3 MB 7.9 MB/s eta 0:00:24\n",
      "   --------------------- ------------------ 205.3/390.3 MB 7.9 MB/s eta 0:00:24\n",
      "   --------------------- ------------------ 207.6/390.3 MB 7.9 MB/s eta 0:00:23\n",
      "   --------------------- ------------------ 210.5/390.3 MB 8.0 MB/s eta 0:00:23\n",
      "   --------------------- ------------------ 213.4/390.3 MB 8.0 MB/s eta 0:00:23\n",
      "   ---------------------- ----------------- 216.0/390.3 MB 8.1 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 219.2/390.3 MB 8.1 MB/s eta 0:00:22\n",
      "   ---------------------- ----------------- 222.0/390.3 MB 8.2 MB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 225.2/390.3 MB 8.2 MB/s eta 0:00:21\n",
      "   ----------------------- ---------------- 228.3/390.3 MB 8.3 MB/s eta 0:00:20\n",
      "   ----------------------- ---------------- 231.5/390.3 MB 8.3 MB/s eta 0:00:20\n",
      "   ------------------------ --------------- 234.6/390.3 MB 8.4 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 236.5/390.3 MB 8.4 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 237.5/390.3 MB 8.3 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 238.6/390.3 MB 8.3 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 239.9/390.3 MB 8.3 MB/s eta 0:00:19\n",
      "   ------------------------ --------------- 241.2/390.3 MB 8.3 MB/s eta 0:00:18\n",
      "   ------------------------ --------------- 242.7/390.3 MB 8.3 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 244.1/390.3 MB 8.3 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 245.6/390.3 MB 8.3 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 247.5/390.3 MB 8.3 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 249.0/390.3 MB 8.2 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 250.9/390.3 MB 8.1 MB/s eta 0:00:18\n",
      "   ------------------------- -------------- 252.7/390.3 MB 8.0 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 254.5/390.3 MB 7.9 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 256.4/390.3 MB 8.0 MB/s eta 0:00:17\n",
      "   -------------------------- ------------- 258.5/390.3 MB 8.0 MB/s eta 0:00:17\n",
      "   -------------------------- ------------- 260.6/390.3 MB 8.1 MB/s eta 0:00:17\n",
      "   -------------------------- ------------- 262.7/390.3 MB 8.1 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 265.0/390.3 MB 8.2 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 267.1/390.3 MB 8.2 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 269.5/390.3 MB 8.3 MB/s eta 0:00:15\n",
      "   --------------------------- ------------ 271.8/390.3 MB 8.3 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 274.2/390.3 MB 8.4 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 276.8/390.3 MB 8.5 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 279.2/390.3 MB 8.5 MB/s eta 0:00:14\n",
      "   ---------------------------- ----------- 282.1/390.3 MB 8.6 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 284.7/390.3 MB 8.7 MB/s eta 0:00:13\n",
      "   ----------------------------- ---------- 287.6/390.3 MB 8.7 MB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 290.2/390.3 MB 8.9 MB/s eta 0:00:12\n",
      "   ------------------------------ --------- 293.1/390.3 MB 9.0 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 296.0/390.3 MB 9.1 MB/s eta 0:00:11\n",
      "   ------------------------------ --------- 299.1/390.3 MB 9.2 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 301.7/390.3 MB 9.3 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 304.9/390.3 MB 9.4 MB/s eta 0:00:10\n",
      "   ------------------------------- -------- 308.0/390.3 MB 9.4 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 311.4/390.3 MB 9.5 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 314.6/390.3 MB 9.6 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 318.0/390.3 MB 9.6 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 319.6/390.3 MB 9.6 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 320.9/390.3 MB 9.6 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 322.2/390.3 MB 9.6 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 323.5/390.3 MB 9.5 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 325.1/390.3 MB 9.5 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 326.6/390.3 MB 9.5 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 328.2/390.3 MB 9.4 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 329.3/390.3 MB 9.4 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 330.8/390.3 MB 9.4 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 332.7/390.3 MB 9.4 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 334.5/390.3 MB 9.3 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 336.3/390.3 MB 9.3 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 338.2/390.3 MB 9.4 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 340.3/390.3 MB 9.9 MB/s eta 0:00:06\n",
      "   ---------------------------------- ---- 342.4/390.3 MB 10.1 MB/s eta 0:00:05\n",
      "   ---------------------------------- ---- 344.5/390.3 MB 10.2 MB/s eta 0:00:05\n",
      "   ---------------------------------- ---- 346.6/390.3 MB 10.3 MB/s eta 0:00:05\n",
      "   ---------------------------------- ---- 348.9/390.3 MB 10.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 351.0/390.3 MB 10.5 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 353.4/390.3 MB 10.5 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 356.0/390.3 MB 10.6 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 358.4/390.3 MB 10.6 MB/s eta 0:00:04\n",
      "   ------------------------------------ -- 361.0/390.3 MB 10.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 363.3/390.3 MB 10.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 366.2/390.3 MB 10.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 368.8/390.3 MB 10.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 371.5/390.3 MB 10.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 374.3/390.3 MB 10.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 377.2/390.3 MB 10.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 380.1/390.3 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  383.0/390.3 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  386.1/390.3 MB 11.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  389.0/390.3 MB 11.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 11.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 11.0 MB/s eta 0:00:01\n",
      "   --------------------------------------- 390.3/390.3 MB 10.8 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.70.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 3.1/4.3 MB 15.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 14.3 MB/s eta 0:00:00\n",
      "Downloading h5py-3.13.0-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.0/3.0 MB 13.3 MB/s eta 0:00:00\n",
      "Downloading keras-3.9.0-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 11.5 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 3.1/26.4 MB 15.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.8/26.4 MB 16.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 10.2/26.4 MB 15.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 13.6/26.4 MB 16.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 16.8/26.4 MB 15.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.6/26.4 MB 14.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 19.9/26.4 MB 13.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.5/26.4 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.8/26.4 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.4/26.4 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.0/26.4 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 10.7 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 1.6/5.5 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.1/5.5 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.7/5.5 MB 7.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 6.5 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.1-cp312-cp312-win_amd64.whl (306 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, markdown, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.70.0 h5py-3.13.0 keras-3.9.0 libclang-18.1.1 markdown-3.7 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.14.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 termcolor-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape[1],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pooja\\miniconda3\\envs\\udemy\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build ANN Model\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(64, activation='relu',input_shape=(X_train.shape[1],)), #HL1\n",
    "        Dense(32, activation='relu'),                                 #HL2\n",
    "        Dense(1, activation='sigmoid')                                #Output Layer\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,945</span> (11.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,945\u001b[0m (11.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,945</span> (11.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,945\u001b[0m (11.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The adam optiimzer comes with a default learning rate and inorder to updatea the learning rate with other values,we can use the following\n",
    "optimizer1 = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "binaryloss1=tf.keras.losses.BinaryCrossentropy\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.complie(optimizer=optimizer1, loss=binary1, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the tensorboard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Earlystopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True) # vall_loss is the validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7464 - loss: 0.5188 - val_accuracy: 0.8330 - val_loss: 0.3844\n",
      "Epoch 2/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8420 - loss: 0.3917 - val_accuracy: 0.8530 - val_loss: 0.3516\n",
      "Epoch 3/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8619 - loss: 0.3432 - val_accuracy: 0.8530 - val_loss: 0.3515\n",
      "Epoch 4/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8686 - loss: 0.3339 - val_accuracy: 0.8590 - val_loss: 0.3413\n",
      "Epoch 5/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8542 - loss: 0.3477 - val_accuracy: 0.8630 - val_loss: 0.3392\n",
      "Epoch 6/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8642 - loss: 0.3331 - val_accuracy: 0.8610 - val_loss: 0.3395\n",
      "Epoch 7/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8688 - loss: 0.3234 - val_accuracy: 0.8590 - val_loss: 0.3395\n",
      "Epoch 8/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8659 - loss: 0.3308 - val_accuracy: 0.8595 - val_loss: 0.3386\n",
      "Epoch 9/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8707 - loss: 0.3225 - val_accuracy: 0.8590 - val_loss: 0.3352\n",
      "Epoch 10/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8659 - loss: 0.3178 - val_accuracy: 0.8590 - val_loss: 0.3380\n",
      "Epoch 11/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8667 - loss: 0.3236 - val_accuracy: 0.8605 - val_loss: 0.3350\n",
      "Epoch 12/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8673 - loss: 0.3153 - val_accuracy: 0.8605 - val_loss: 0.3377\n",
      "Epoch 13/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8647 - loss: 0.3225 - val_accuracy: 0.8630 - val_loss: 0.3365\n",
      "Epoch 14/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8659 - loss: 0.3187 - val_accuracy: 0.8635 - val_loss: 0.3392\n",
      "Epoch 15/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8748 - loss: 0.3103 - val_accuracy: 0.8600 - val_loss: 0.3363\n",
      "Epoch 16/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8739 - loss: 0.3080 - val_accuracy: 0.8610 - val_loss: 0.3354\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test,y_test),\n",
    "                    validation_split=0.2, \n",
    "                    epochs=100, \n",
    "                    batch_size=32, \n",
    "                    callbacks=[early_stopping, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard Extension\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5844), started 0:10:59 ago. (Use '!kill 5844' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9fb03ba3128188b9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9fb03ba3128188b9\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
